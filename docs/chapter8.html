<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Chapter 8 ‚Äì Stats Textbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter9.html" rel="next">
<link href="./chapter7.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-f2c6d6e2b784ddc5de38779acc06f37d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter8.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Chapter 8</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Stats Textbook</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Chapter 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Chapter 2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chapter 3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Chapter 4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Chapter 5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Chapter 6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Chapter 7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter8.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Chapter 8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Chapter 9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Chapter 10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chapter 11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Chapter 12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Chapter 13</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Chapter 14</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#evaluating-group-averages-against-a-benchmark-one-sample-t-test-and-goodness-of-fit-analysis" id="toc-evaluating-group-averages-against-a-benchmark-one-sample-t-test-and-goodness-of-fit-analysis" class="nav-link active" data-scroll-target="#evaluating-group-averages-against-a-benchmark-one-sample-t-test-and-goodness-of-fit-analysis">Evaluating Group Averages Against a Benchmark: One-Sample t Test and Goodness-of-Fit Analysis</a>
  <ul class="collapse">
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li><a href="#example-conducting-one-sample-t-test" id="toc-example-conducting-one-sample-t-test" class="nav-link" data-scroll-target="#example-conducting-one-sample-t-test"><span class="header-section-number">8.1</span> Example: Conducting one sample t-test</a>
  <ul class="collapse">
  <li><a href="#step-4" id="toc-step-4" class="nav-link" data-scroll-target="#step-4">Step 4</a></li>
  </ul></li>
  <li><a href="#reporting-results-in-apa-format" id="toc-reporting-results-in-apa-format" class="nav-link" data-scroll-target="#reporting-results-in-apa-format"><span class="header-section-number">8.2</span> Reporting Results in APA Format</a></li>
  <li><a href="#cautions-with-one-sided-tests" id="toc-cautions-with-one-sided-tests" class="nav-link" data-scroll-target="#cautions-with-one-sided-tests"><span class="header-section-number">8.3</span> Cautions with One-Sided Tests</a></li>
  <li><a href="#understanding-effect-size" id="toc-understanding-effect-size" class="nav-link" data-scroll-target="#understanding-effect-size"><span class="header-section-number">8.4</span> Understanding Effect Size</a></li>
  <li><a href="#calculating-estimated-cohens-d" id="toc-calculating-estimated-cohens-d" class="nav-link" data-scroll-target="#calculating-estimated-cohens-d"><span class="header-section-number">8.5</span> Calculating Estimated Cohen‚Äôs d</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals"><span class="header-section-number">8.6</span> Confidence Intervals</a>
  <ul class="collapse">
  <li><a href="#interpreting-confidence-intervals" id="toc-interpreting-confidence-intervals" class="nav-link" data-scroll-target="#interpreting-confidence-intervals"><span class="header-section-number">8.6.1</span> Interpreting Confidence Intervals</a></li>
  <li><a href="#calculating-confidence-intervals" id="toc-calculating-confidence-intervals" class="nav-link" data-scroll-target="#calculating-confidence-intervals"><span class="header-section-number">8.6.2</span> Calculating Confidence Intervals</a></li>
  <li><a href="#using-a-confidence-interval-to-evaluate-a-null-hypothesis" id="toc-using-a-confidence-interval-to-evaluate-a-null-hypothesis" class="nav-link" data-scroll-target="#using-a-confidence-interval-to-evaluate-a-null-hypothesis"><span class="header-section-number">8.6.3</span> Using a Confidence Interval to Evaluate a Null Hypothesis</a></li>
  <li><a href="#using-a-confidence-interval-to-evaluate-a-null-hypothesis-1" id="toc-using-a-confidence-interval-to-evaluate-a-null-hypothesis-1" class="nav-link" data-scroll-target="#using-a-confidence-interval-to-evaluate-a-null-hypothesis-1"><span class="header-section-number">8.6.4</span> Using a Confidence Interval to Evaluate a Null Hypothesis</a></li>
  </ul></li>
  <li><a href="#chi-square-goodness-of-fit-test" id="toc-chi-square-goodness-of-fit-test" class="nav-link" data-scroll-target="#chi-square-goodness-of-fit-test"><span class="header-section-number">8.7</span> Chi-Square Goodness-of-Fit Test</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">8.8</span> Conclusion</a>
  <ul class="collapse">
  <li><a href="#key-takeaways-for-educational-researchers-from-chapter-8" id="toc-key-takeaways-for-educational-researchers-from-chapter-8" class="nav-link" data-scroll-target="#key-takeaways-for-educational-researchers-from-chapter-8"><span class="header-section-number">8.8.1</span> Key Takeaways for Educational Researchers from Chapter 8</a></li>
  </ul></li>
  <li><a href="#key-definitions-for-chapter-8" id="toc-key-definitions-for-chapter-8" class="nav-link" data-scroll-target="#key-definitions-for-chapter-8"><span class="header-section-number">8.9</span> Key Definitions for Chapter 8</a></li>
  <li><a href="#check-your-understanding" id="toc-check-your-understanding" class="nav-link" data-scroll-target="#check-your-understanding"><span class="header-section-number">8.10</span> Check Your Understanding</a></li>
  </ul></li>
  <li><a href="#chapter-8-one-sample-t-test-and-goodness-of-fit-analysis-in-r" id="toc-chapter-8-one-sample-t-test-and-goodness-of-fit-analysis-in-r" class="nav-link" data-scroll-target="#chapter-8-one-sample-t-test-and-goodness-of-fit-analysis-in-r">Chapter 8: One-Sample t Test and Goodness-of-Fit Analysis in R</a>
  <ul class="collapse">
  <li><a href="#one-sample-t-test" id="toc-one-sample-t-test" class="nav-link" data-scroll-target="#one-sample-t-test">1 One-Sample t Test</a>
  <ul class="collapse">
  <li><a href="#define-hypothesis" id="toc-define-hypothesis" class="nav-link" data-scroll-target="#define-hypothesis">1.1 Define Hypothesis</a></li>
  <li><a href="#conduct-the-test" id="toc-conduct-the-test" class="nav-link" data-scroll-target="#conduct-the-test">1.2 Conduct the Test</a></li>
  <li><a href="#calculate-effect-size-cohens-d" id="toc-calculate-effect-size-cohens-d" class="nav-link" data-scroll-target="#calculate-effect-size-cohens-d">1.3 Calculate Effect Size (Cohen‚Äôs d)</a></li>
  </ul></li>
  <li><a href="#chi-square-goodness-of-fit-test-1" id="toc-chi-square-goodness-of-fit-test-1" class="nav-link" data-scroll-target="#chi-square-goodness-of-fit-test-1">2 Chi-Square Goodness-of-Fit Test</a>
  <ul class="collapse">
  <li><a href="#define-hypothesis-1" id="toc-define-hypothesis-1" class="nav-link" data-scroll-target="#define-hypothesis-1">2.1 Define Hypothesis</a></li>
  <li><a href="#conduct-the-test-1" id="toc-conduct-the-test-1" class="nav-link" data-scroll-target="#conduct-the-test-1">2.2 Conduct the Test</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Chapter 8</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="evaluating-group-averages-against-a-benchmark-one-sample-t-test-and-goodness-of-fit-analysis" class="level1 unnumbered">
<h1 class="unnumbered">Evaluating Group Averages Against a Benchmark: One-Sample t Test and Goodness-of-Fit Analysis</h1>
<section id="learning-objectives" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="learning-objectives">Learning Objectives</h2>
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li><p>Describe the differences between z tests and t tests, including when to use each based on knowledge of population parameters and sample characteristics.</p></li>
<li><p>Calculate and interpret the test statistic, p value, and effect size for one-sample t tests and goodness-of-fit analyses.</p></li>
<li><p>Clearly explain the distinction between statistical significance and practical significance, and evaluate both to provide a comprehensive understanding of research findings.</p></li>
<li><p>Use confidence intervals to quantify uncertainty in sample mean estimates and evaluate the plausibility of a null hypothesis.</p></li>
</ul>
<hr>
<p>We just learned about z tests in the previous chapter, which you can conduct if you want to compare a sample mean to a population with a known mean and standard deviation. Often, however, we do not know the population standard deviation (œÉ), and we must estimate it with the sample statistic, in this case sample standard deviation (s). When this happens, we can no longer rely on the standard normal distribution, also called the z distribution, as it assumes precise knowledge of œÉ. Instead, we use a t distribution, which accounts for the added uncertainty of estimating œÉ. In these cases, we use a t distribution, which closely resembles its z-distribution counterpart but with two key differences.</p>
<p>First, the tail ends of the t distribution take longer to approach the X-axis compared to the z distribution. This is because we are estimating the population standard deviation, and that means we have more uncertainty. If you look at figure 8.1, imagine drawing a vertical line out towards one of the ends. Can you see how there would be more area under the curve for the t distribution with just 5 degrees of freedom? Shaded areas under the curve represent 5% of the total area. This means the sample mean must be farther from the population mean before we can confidently conclude that the observed difference reflects something other than random chance.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter8_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Fig 8.1: Comparison of Standard Normal and t-Distributions</figcaption>
</figure>
</div>
</div>
</div>
<p>Second, there is more than one t distribution, and the shape of the distribution depends on your sample size. Recall that a larger sample size leads to a smaller standard error, which in turn increases your statistical power to detect a significant effect. You can see how different t distributions look in figure 8.1. The larger the sample size, the closer the t distribution becomes to a z distribution. Once n &gt; 120, the two distributions are almost identical. Having such a large sample makes up for the fact that we are estimating the population standard deviation.</p>
<p>Another way to look at this is that the t distribution is related to the degrees of freedom. You must know the degrees of freedom to utilize a t table. Since sample standard deviation is used to compute the estimate of standard error, the degrees of freedom for a t test are calculated by using n - 1.</p>
</section>
<section id="example-conducting-one-sample-t-test" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="example-conducting-one-sample-t-test"><span class="header-section-number">8.1</span> Example: Conducting one sample t-test</h2>
<p>Now, let‚Äôs walk through an example of conducting a one-sample t test. Let‚Äôs think back to the example from the last chapter, where we compared a sample mean to a population mean with the z test. We have a similar, but slightly different, scenario this time. We have a sample of just 35 test scores from a single third grade class. The teacher is concerned that their students are underperforming in English Language Arts (ELA) and hypothesize their class will score below the state average of 440. When the results were returned to the school, the class‚Äôs average score was 425.26. Is this average significantly lower than the expected value of 440? Let‚Äôs conduct a hypothesis test to find out.</p>
<section id="step-1-determine-the-null-and-alternative-hypotheses." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-1-determine-the-null-and-alternative-hypotheses.">Step 1: Determine the null and alternative hypotheses.</h4>
<p>Just like last time, the null hypothesis is that there is no difference between the teacher‚Äôs class and the overall state population. So, the null hypothesis is:</p>
<p><span class="math display">\[
H_0: \mu = 440
\]</span></p>
<p>This time, however, we are going to use a directional, or one-tailed test, because the teacher is specifically concerned that the students are scoring lower than the general population. So, the alternative hypothesis is:</p>
<p><span class="math display">\[
H_1: \mu &lt; 440
\]</span></p>
<p>There are 35 students in this class, which might be why they are not doing so well, so n = 35. The sampling distribution in this case would be composed of the means of all possible samples of size n = 35 taken from the state population of third graders. It would be centered at Œº = 440 (the population mean, which we know), but we must calculate the standard error using the sample standard deviation. The sample standard deviation (s) happens to be 44.994.</p>
<p><span class="math display">\[
\frac{s}{\sqrt{n}} = \frac{44.994}{\sqrt{35}} = 7.605
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter8_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Fig 8.2: Comparison of Sampling Distribution (t, df=34) and Normal Distribution</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="step-2-set-the-criteria-for-a-decision." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-2-set-the-criteria-for-a-decision.">Step 2: Set the criteria for a decision.</h4>
<p>We will set the alpha level (Œ±) to 0.05. So, we will reject the null hypothesis if the p value is less than 0.05. Since we are conducting a one-sided directional test, the entire rejection region is in the left tail of the distribution. To find the critical value we first need to consider our degrees of freedom. For a t test, df = n ‚Äì 1, so we have 34 degrees of freedom. In the Critical Values of t distribution table in the appendix, there is no line for df = 34, so round down to the nearest degrees of freedom (30) as a conservative estimate. If you use an online calculator, which allows you to enter precise degrees of freedom, you will find that the critical value for 34 degrees of freedom at a .05 alpha level is -1.69. It is negative because we expect the sample mean to be lower than the population mean.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter8_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Sampling Distribution of the Sample Mean (n=35)</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="step-3-check-assumptions-and-compute-the-test-statistic." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-3-check-assumptions-and-compute-the-test-statistic.">Step 3: Check assumptions and compute the test statistic.</h4>
<p>There are three assumptions underlying this test. They are:</p>
<ol type="1">
<li><p>Random sampling: The scores come from a random, representative sample.</p></li>
<li><p>Independence: The scores are independent of one another.</p></li>
<li><p>Normality: The population score distribution is approximately normal.</p></li>
</ol>
<p>It is okay that we didn‚Äôt choose a random sample representing all third graders in the state because the inferences we will draw are only about this one class. We can‚Äôt see the entire population distribution, but the histogram for the scores looks almost perfectly normal.</p>
<p>(fig 4 here)</p>
<p>If the distribution was way off, we could still proceed but be very cautious about our interpretation of the results. Since our sample size is greater than 30, we would be okay even without such a normal distribution due to the central limit theorem. So, we are all set to calculate our test statistic.</p>
<p>For the one-sample t test, we use the formula:</p>
<p><span class="math display">\[
t = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}}
\]</span></p>
<p>Notice that the formula is very similar to what we used to calculate the z statistic. The only difference is that we now estimate the standard error using the sample standard deviation and sample size in the denominator because we don‚Äôt know the value of the population standard deviation (ùúé).</p>
<p>The numerator represents the difference between the observed and test value specified in the null hypothesis. The symbol ùúá represents the population parameter specified in the hypothesis, often referred to as the null value, as it reflects the assumed true population mean under the null hypothesis. The other values for the test statistic come from our sample data.</p>
<p><span class="math display">\[
t
= \frac{425.26 - 440}{\dfrac{44.994}{\sqrt{35}}}
= \frac{-14.74}{7.605}
= -1.938
\]</span></p>
</section>
<section id="step-4" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-4">Step 4</h3>
<section id="a-find-the-p-value." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="a-find-the-p-value.">a: Find the p value.</h4>
<p>We must now determine whether our t statistic is significant, which would mean that it is very unlikely we obtained this value due to chance alone. In step 2, we said that the critical value for this test was -1.69. Picture a t distribution and draw a vertical line about 1.7 standard deviations below the mean. Anything to the left of that is in the rejection region. Is our t statistic of -1.938 in the rejection region? Yes ‚Äì it is farther away from the center than our critical value. This means our p value is less than 0.05.</p>
<p>(fig 8.5 here)</p>
</section>
<section id="b-draw-a-conclusion-and-report-your-conclusion." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="b-draw-a-conclusion-and-report-your-conclusion.">b: Draw a conclusion and report your conclusion.</h4>
<p>Given that our p value is less than 0.05, the appropriate decision is to reject the null hypothesis. In other words, we have found evidence in favor of the alternative hypothesis. Students in this class scored significantly lower than the overall state population on the test. Let‚Äôs assume we use statistical software to land on a p value of 0.03 for this analysis.</p>
</section>
</section>
</section>
<section id="reporting-results-in-apa-format" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="reporting-results-in-apa-format"><span class="header-section-number">8.2</span> Reporting Results in APA Format</h2>
<p>The American Psychological Association, 7th edition (APA, 2019) has decided that there is a correct way to report the results of a t test. In this case, you would report the results of our test like this: Scores for students in this third-grade class (M = 425.26) were significantly lower than scores of third graders statewide, t(34) = -1.938, p = 0.03.</p>
<p>The most important part of the reporting is the section that starts with the observed t statistic. You put the degrees of freedom in parentheses immediately following the t; all statistics (e.g., M, t, p) are in italics, and you report the p value after the exact t statistic. Remember, that even if the statistical software says p = 0.000, you should never report that. Instead, you should report p &lt; 0.001. You can also just report that p &lt; 0.05 (your alpha level) if you do not have access to statistical software.</p>
</section>
<section id="cautions-with-one-sided-tests" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="cautions-with-one-sided-tests"><span class="header-section-number">8.3</span> Cautions with One-Sided Tests</h2>
<p>One caution with directional, one-tailed tests is that you need to decide on one-tailed versus two-tailed tests up front. It is really not okay to decide after you see the results that you are going to conduct a one-tailed test. You should only be conducting a one-tailed test if you have good reason to expect the sample mean to be lower or higher than, rather than just different from, the population mean. And while a one-tailed test has greater power to detect a significant result, there is risk involved. Imagine that we expected the sample mean to be significantly lower, but it turned out to be significantly higher than the population mean. If we had been conducting a two-tailed test, that would be a significant difference from the population mean. But since our alternative hypothesis was that Œº &lt; 440, we would fail to reject the null (non-significant result). Most of the time you will be using a two-tailed test for the possibility of a difference in either direction. Only use a one-tailed test if you have a very good reason and you decide ahead of time to do so.</p>
<p>Another caution is that type III error is introduced when using directional tests. Type III error occurs when a correct conclusion is drawn for the wrong reason or when the wrong question is asked, and a statistically valid result is obtained for that incorrect question. For example, a school district wants to determine whether lessons learned from a new professional development program will reduce the time teachers spend on grading. After collecting data and running a statistical test, the null hypothesis (that the program has no effect on grading time) is rejected, and a significant difference was found. District leadership interpreted this result as evidence that the program was reducing grading time, so they decided to expand the program. However, a few weeks later, teachers were demanding that the district take a closer look at the data because they claimed to be spending more time grading. Sure enough, district leadership found they made a mistake: while the statistical test correctly identified a significant difference in grading time (rejecting the null hypothesis), they misinterpreted the direction of the effect. The program increased grading time instead of reducing it. This misinterpretation of the direction of the significant effect is a Type III error: correctly rejecting the null hypothesis but misunderstanding what the result actually implies.</p>
</section>
<section id="understanding-effect-size" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="understanding-effect-size"><span class="header-section-number">8.4</span> Understanding Effect Size</h2>
<p>Hypothesis testing is important for knowing if there is a significant difference between a sample and the population, but it will not tell you how big the difference is. A hypothesis test will almost always return a significant result when you have a large sample size because a test statistic is a function of standard error, which decreases as sample size increases.</p>
<p>Given the mean difference and standard deviation remain the same, as sample size increases, the test statistic always increases. For example, if you wanted to conduct a one-sample t test with a sample mean of 22 and a SD of 2 compared to a population mean of 23.5, you are sure to get a statistically significant result when n = 100,000 even if the p value is &gt; 0.05 when n = 10. It is somewhat paradoxical that with sufficiently large sample size, the statistical power becomes strong enough to flag even small differences as significant, even if those differences are practically trivial or meaningless. Therefore, it is important to have another way to represent the meaningfulness, or practical significance, of a statistically significant result. That is why we calculate and report effect size.</p>
<p>Of course, one way of understanding the size of the difference is to simply compare the sample mean and population mean on the original measurement scale. Someone who understands a particular testing instrument could make their own judgment as to whether a difference of about 15 points was meaningful, or cause for concern. But it helps to have a common language for reporting effect size, and the way we do that is to standardize the effect.</p>
<p>Effect size is a numeric measure that indicates the strength or meaningfulness of the relationship or difference between variables in a study. Unlike p values, which only tell you whether an effect exists, effect size tells you how large or meaningful that effect is. It provides a standardized way to understand the practical significance of research findings, which is particularly useful when comparing results across studies.</p>
<p>Estimated Cohen‚Äôs d is a common measure of effect size for t tests. We hope you remember back in chapter 5 when we learned about z scores, which are also known as standardized scores because they are measured in standard deviation units. When we use estimated Cohen‚Äôs d as a measure of effect size, we are doing the same thing. Cohen‚Äôs d quantifies the magnitude of the difference between two means relative to the variability in the data and provides a standardized measure of practical significance, helping to interpret the importance of the result by allowing us to express the effect size in terms of standard deviation units. This approach provides a common scale, making it easier to compare results across different tests or measures, rather than relying on raw score differences.</p>
</section>
<section id="calculating-estimated-cohens-d" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="calculating-estimated-cohens-d"><span class="header-section-number">8.5</span> Calculating Estimated Cohen‚Äôs d</h2>
<p>One quick note to get us started ‚Äì we are being careful to refer to the effect size we use for t tests as estimated Cohen‚Äôs d to distinguish it from Cohen‚Äôs d used in z tests. This distinction arises because effect sizes for t tests are calculated using sample data, whereas z tests rely on known population parameters. But out in the world of educational research, you will normally just hear it called Cohen‚Äôs d regardless of the type of analysis used.</p>
<p>Here is the formula for estimated Cohen‚Äôs d for a one-sample t test:</p>
<p><span class="math display">\[
d = \frac{\bar{X} - \mu}{SD}
\]</span></p>
<p>In our example above, the sample mean (XÃÖ) = 425.26 and SD = 44.994. The population mean (Œº) = 440. Using the formula,</p>
<p><span class="math display">\[
d
= \frac{425.26 - 440}{44.994}
= -0.33
\]</span></p>
<p>That is, our effect size is -0.33, which according to the following table from Privitera (2018) is a medium effect size. In our sample research question, this means the students in the third-grade class had scores that were about one-third of a standard deviation below the state average. A positive effect size indicates the sample mean was larger than the population mean, and a negative effect size indicates it was smaller. Since effect size can be negative, you need to consider the absolute value when making a judgement about the strength of the effect.</p>
<p><strong>Cohen‚Äôs Effect Size Conventions</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Description of Effect</th>
<th>Effect Size (d)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Small</td>
<td>( d &lt; 0.2 )</td>
</tr>
<tr class="even">
<td>Medium</td>
<td>( 0.2 &lt; d &lt; 0.8 )</td>
</tr>
<tr class="odd">
<td>Large</td>
<td>( d &gt; 0.8 )</td>
</tr>
</tbody>
</table>
<p><em>Source:</em> Adapted from Privitera, G. J. (2018). <em>Statistics for the Behavioral Sciences</em> (3rd ed.). SAGE Publications.</p>
<p>Before we move on, we want to remind you of a few other similar formulas because we had a tendency to get them confused in the past. First, here is a reminder of the formula for calculating z scores:</p>
<p><span class="math display">\[
z = \frac{X - \mu}{\sigma}
\]</span></p>
<p>Do you see the differences between that and the formula used to calculate Cohen‚Äôs d? First, with a z score, we only have one X (i.e., a particular value), rather than a sample mean, or XÃÖ. But even more importantly, we use the population standard deviation (œÉ) rather than the sample SD to calculate a z score. But overall, the concept is exactly the same: both z scores and Cohen‚Äôs d involve converting a raw difference from the mean into standard deviation units. The key difference lies in the specific inputs used for calculations.</p>
<p>Do you see the differences between that and the formula used to calculate Cohen‚Äôs d? First, with a z score, we only have one X (i.e., a particular value), rather than a sample mean, or XÃÖ. But even more importantly, we use the population standard deviation (œÉ) rather than the sample SD to calculate a z score. But overall, the concept is exactly the same: both z scores and Cohen‚Äôs d involve converting a raw difference from the mean into standard deviation units. The key difference lies in the specific inputs used for calculations.</p>
<p>Another place we have seen learners, including ourselves, get tripped up is confusing the formula for Cohen‚Äôs d with the formula for the t statistic itself. Here they are, side by side:</p>
<p><span class="math display">\[
\begin{aligned}
d = \frac{\bar{X}-\mu}{SD}, \quad
t = \frac{\bar{X}-\mu}{\dfrac{s}{\sqrt{n}}}
\end{aligned}
\]</span></p>
<p>Even though the first formula, Cohen‚Äôs d, uses SD to represent the sample standard deviation, and the second, t statistic, uses s, they represent the same value. So, the only difference is that d has nothing to do with sample size, but sample size (n) is hugely important in calculating standard error, which is the denominator for the t statistic. For Cohen‚Äôs d, the mean difference is divided by the standard deviation, which represents the variability in the actual scores within the sample. For the t statistic, the mean difference is divided by the standard error, which represents the standard deviation of the theoretical sampling distribution. By definition, it is going to be much smaller than the original sample standard deviation.</p>
<p>In this example, the same mean difference (-14.743) served as the numerator for both d and t. When we divided it by standard error for the t statistic, we got -1.938. This told us how far our sample mean was from the center of the sampling distribution. When we divided it by the sample standard deviation for Cohen‚Äôs d, we got -0.33, which told us how far our sample mean was from the population mean, the center of the population distribution.</p>
<p>If nothing else, we hope this helps you see why we need both effect size and hypothesis tests. Effect size tells us how big a difference is while the hypothesis test tells us whether we can be confident the difference is a result of something other than chance. Effect size does not depend on sample size, but you are more likely to get a significant result from your hypothesis test as you increase the sample size.</p>
<p>It is common to report effect size after the results of your hypothesis test. For example, scores for students in this third-grade class (M = 425.26) were significantly lower than scores of third graders statewide, t(34) = -1.938, p = 0.03, d = -0.33. You might also choose to report the significant result followed by a statement that Cohen‚Äôs d (-0.33) indicated a medium effect size. Keep in mind that if you have a small sample size, you might be able to calculate a large effect size even without a significant result. This can be interesting to learn and might suggest you should try to conduct your analysis again with a larger sample size. But we don‚Äôt report effect size after a non-significant result since it does not make sense to describe the size of an effect you just concluded does not exist.</p>
</section>
<section id="confidence-intervals" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="confidence-intervals"><span class="header-section-number">8.6</span> Confidence Intervals</h2>
<p>How do confidence intervals fit in? Confidence intervals provide an additional layer of transparency by offering a range of values likely to contain the true population parameter.</p>
<p>The way we think about it, the reason we use confidence intervals is to be up front about our level of uncertainty. We take a sample and report the mean, but how confident are we that the mean of our sample is equal to the true population mean? Or we have two samples and we find the difference between the two means (stay tuned for the next chapter), but how confident are we that we know the true difference? If we report a point estimate (e.g., a mean) along with an interval estimate, we are being completely transparent about how good our estimate is likely to be.</p>
<p>Another high-level concept to be aware of before we dive into the details is the balance between precision and accuracy. Say we want to estimate the average height of all people in the entire world who are 18 and older. We could be highly confident in our accuracy if we estimated that the mean height of all adults was somewhere between 2 feet (60.96cm) and 8 feet (243.84cm) . Don‚Äôt you feel pretty comfortable accepting that the true population mean is somewhere within that interval? And yet, do you feel like you have learned any useful information? Probably not, because our estimate has almost zero precision. We could go in another direction and estimate that the average height was exactly 65.8 inches (167.13cm). That estimate is much more precise, but who knows how accurate it is?</p>
<p>What we often do is report both point and interval estimates. We commonly see this with survey results. We start with a sample mean and then use the standard error to calculate a confidence interval. The more confident we are (higher level of accuracy), the wider the interval (less precision). We can decide on any confidence level we want and calculate the exact interval, but it is most common to use 90, 95, or 99%.</p>
<section id="interpreting-confidence-intervals" class="level3" data-number="8.6.1">
<h3 data-number="8.6.1" class="anchored" data-anchor-id="interpreting-confidence-intervals"><span class="header-section-number">8.6.1</span> Interpreting Confidence Intervals</h3>
<p>Now that you have the general idea about the purpose of confidence intervals, we are going to get a little pedantic and refer you to the words of <a href="https://digitalcommons.unl.edu/cgi/viewcontent.cgi?referer=&amp;httpsredir=1&amp;article=1009&amp;context=imseteach">Dr.&nbsp;Paul Savory (2008)</a>. Say you want to know the mean of some variable in the population. You take a sample, find the mean, and then create a 95% confidence interval around it. It is incorrect to say, ‚ÄúThere is a 95% probability that Œº falls within this interval.‚Äù This is incorrect because it implies that Œº is random and could take on different values. In fact, Œº is a constant ‚Äì we just don‚Äôt know what it is ‚Äì and it either falls within our interval or it doesn‚Äôt. The correct interpretation is, ‚ÄúWe are confident that if Œº were known, this interval would contain it.‚Äù This may seem like a trivial difference, but it makes an important point that the probability or confidence level we report is referring to the interval, not the population parameter itself.</p>
<p>We highly recommend visiting the book‚Äôs website to test out the <a href="no link right now :/">confidence intervals applet</a> for a helpful visualization of the concept. The way the applet works is that you select the confidence level and sample size, and then it will randomly pull one or 25 samples from the population distribution. If you request 25 samples, you will see them all lined up. Each sample will have a mean and corresponding confidence interval around it.</p>
<p>We used a 90% confidence interval with a sample size of 10 in the following example and asked the applet to take 25 samples, see figure 8.6. Almost all resulting samples had a confidence interval that contained the true population mean, but two did not. Note that 23/25 is 92% and not 90%, but when we try again, sometimes we get 24/25 or 22/25. Even our 90% confidence interval is just an estimate. The applet provides a great visualization of the difference between the original population distribution and the sampling distribution. You recommend playing around in the applet to see how increasing the confidence level and/or the sample size will typically result in a greater percentage of possible sample intervals containing the true population mean.</p>
<p>(fig 8.6 here)</p>
</section>
<section id="calculating-confidence-intervals" class="level3" data-number="8.6.2">
<h3 data-number="8.6.2" class="anchored" data-anchor-id="calculating-confidence-intervals"><span class="header-section-number">8.6.2</span> Calculating Confidence Intervals</h3>
<p>We are going to be calculating confidence intervals around a sample mean, but keep in mind that you can estimate a confidence interval around other statistics as well, such as a mean difference or an odds ratio. Here is how we estimate an unknown population mean using a confidence interval (CI) when population standard deviation is unknown:</p>
<p><span class="math display">\[
\text{CI for Population Mean}
=
\text{Sample Mean}
\;\pm\;
(\text{Level of Confidence}) \times (\text{Standard Error})
\]</span></p>
<p>In mathematical terms:</p>
<p><span class="math display">\[
CI(\mu) = \bar{X} \pm t_{\text{critical}} \times \frac{s}{\sqrt{n}}
\]</span></p>
<p>So, there are three steps to estimate a confidence interval for a population mean.</p>
<ol type="1">
<li><p>Compute the sample mean and standard error.</p></li>
<li><p>Choose the level of confidence and find the critical values of the t distribution for that level.</p></li>
<li><p>Compute the estimation formula to find the upper and lower confidence interval limits.</p></li>
</ol>
<p>The width of our interval depends on several factors: how confident we want to be, the size of our sample, and the variability (or standard deviation) of scores within our sample.</p>
<p>Let‚Äôs work through an example. Suppose you selected a sample of 100 participants and computed sample statistics. You found a sample mean of 4 and SD of 5. Now, you want to estimate a confidence interval around that mean.</p>
<section id="step-1-compute-the-sample-mean-and-standard-error" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-1-compute-the-sample-mean-and-standard-error">Step 1: Compute the sample mean and standard error</h4>
<p>From the information above, we already know that XÃÖ = 4, SD = 5, and n = 100, so we can calculate the standard error as follows:</p>
<p><span class="math display">\[
\frac{s}{\sqrt{n}} = \frac{5}{\sqrt{100}} = 0.5
\]</span></p>
</section>
<section id="step-2-choose-the-level-of-confidence-and-find-critical-values" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-2-choose-the-level-of-confidence-and-find-critical-values">Step 2: Choose the level of confidence and find critical values</h4>
<p>How do we know what level of confidence to choose? This is where you must balance precision and accuracy. In social science research we typically use a 95% level of confidence, which as you saw is consistent with our typical practice of choosing an alpha level of 0.05 for hypothesis testing.</p>
<p>We look to the Critical Values of t Distribution Table in the appendix to find the critical value. Find the t value for a 95% level of significance for a two-tailed test with df = 99. There is no row for 99 degrees of freedom in the table, so we will use df = 100 for an approximation, and we get the t value of 1.98.</p>
</section>
<section id="step-3-compute-the-estimation-formula-to-find-upper-and-lower-confidence-interval-limits." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-3-compute-the-estimation-formula-to-find-upper-and-lower-confidence-interval-limits.">Step 3: Compute the estimation formula to find upper and lower confidence interval limits.</h4>
<p>Using these numbers in the formula from earlier in the chapter, we get:</p>
<p><span class="math display">\[
4 \pm 1.98 \times 0.5 = (3.01,\; 4.99)
\]</span></p>
<p>We can conclude that we are 95% confident the interval of 3.01 to 4.99 contains the true population mean.</p>
</section>
</section>
<section id="using-a-confidence-interval-to-evaluate-a-null-hypothesis" class="level3" data-number="8.6.3">
<h3 data-number="8.6.3" class="anchored" data-anchor-id="using-a-confidence-interval-to-evaluate-a-null-hypothesis"><span class="header-section-number">8.6.3</span> Using a Confidence Interval to Evaluate a Null Hypothesis</h3>
<p>We are going to walk through one more scenario using our original one-sample t test example. This example will demonstrate how estimation through confidence intervals is connected to hypothesis testing, showing that both methods can provide related insights into evaluating a null hypothesis.</p>
<section id="step-1-compute-the-sample-mean-and-standard-error-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-1-compute-the-sample-mean-and-standard-error-1">Step 1: Compute the sample mean and standard error</h4>
<p>We already calculated the relevant values, but to get everything back in one place, our sample mean was XÃÖ = 425.26, our standard error was 7.605, and we wanted to know if our sample mean could be considered equal to the population mean of 440.</p>
</section>
<section id="step-2-choose-the-level-of-confidence-and-find-critical-values-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-2-choose-the-level-of-confidence-and-find-critical-values-1">Step 2: Choose the level of confidence and find critical values</h4>
<p>How do we know what level of confidence to choose? This is where you must balance precision and accuracy. In social science research we typically use a 95% level of confidence, which as you saw is consistent with our typical practice of choosing an alpha level of 0.05 for hypothesis testing.</p>
<p>We look to the Critical Values of t Distribution Table in the appendix to find the critical value. Find the t value for a 95% level of significance for a two-tailed test with df = 99. There is no row for 99 degrees of freedom in the table, so we will use df = 100 for an approximation, and we get the t value of 1.98.</p>
</section>
<section id="step-3-compute-the-estimation-formula-to-find-upper-and-lower-confidence-interval-limits" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-3-compute-the-estimation-formula-to-find-upper-and-lower-confidence-interval-limits">Step 3: Compute the estimation formula to find upper and lower confidence interval limits</h4>
<p>Using these numbers in the formula from earlier in the chapter, we get:</p>
<p><span class="math display">\[
4 \pm 1.98 \times 0.5 = (3.01,\; 4.99)
\]</span></p>
<p>We can conclude that we are 95% confident the interval of 3.01 to 4.99 contains the true population mean.</p>
</section>
</section>
<section id="using-a-confidence-interval-to-evaluate-a-null-hypothesis-1" class="level3" data-number="8.6.4">
<h3 data-number="8.6.4" class="anchored" data-anchor-id="using-a-confidence-interval-to-evaluate-a-null-hypothesis-1"><span class="header-section-number">8.6.4</span> Using a Confidence Interval to Evaluate a Null Hypothesis</h3>
<p>We are going to walk through one more scenario using our original one-sample t test example. This example will demonstrate how estimation through confidence intervals is connected to hypothesis testing, showing that both methods can provide related insights into evaluating a null hypothesis.</p>
<section id="step-1-compute-the-sample-mean-and-standard-error-2" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-1-compute-the-sample-mean-and-standard-error-2">Step 1: Compute the sample mean and standard error</h4>
<p>We already calculated the relevant values, but to get everything back in one place, our sample mean was XÃÖ = 425.26, our standard error was 7.605, and we wanted to know if our sample mean could be considered equal to the population mean of 440.</p>
</section>
<section id="step-2-choose-the-level-of-confidence-and-find-critical-values-2" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-2-choose-the-level-of-confidence-and-find-critical-values-2">Step 2: Choose the level of confidence and find critical values</h4>
<p>When we conducted the t test, we decided to use a directional test. This time for creating a confidence interval, we will use the critical value associated with a two-tailed test. So, we need to find the t value for a 95% level of significance for a two-tailed test with df = 34. Our table doesn‚Äôt have a row for df = 34, so we will use df = 30 for a conservative approximation, and we get the t value of 2.042. Note that the exact critical t value for df = 34 at a 95% confidence level is t = 2.032.</p>
</section>
<section id="step-3-compute-the-estimation-formula-to-find-upper-and-lower-confidence-interval-limits.-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-3-compute-the-estimation-formula-to-find-upper-and-lower-confidence-interval-limits.-1">Step 3: Compute the estimation formula to find upper and lower confidence interval limits.</h4>
<p>Using the numbers from earlier in the chapter, we get: <span class="math display">\[
425.26 \pm 2.042 \times 7.605 = (409.73,\; 440.79)
\]</span></p>
<p>If the value of the population parameter we started with (Œº = 440) is contained within our 95% confidence interval, then we cannot reject the null hypothesis. As you can see, 440 is just barely contained within our 95% confidence interval. If we had used a two-tailed test instead of a one-tailed test earlier, we would have failed to reject the null hypothesis. This reinforces the importance of identifying one-tailed or two-tailed tests before running your statistical analysis.</p>
</section>
</section>
</section>
<section id="chi-square-goodness-of-fit-test" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="chi-square-goodness-of-fit-test"><span class="header-section-number">8.7</span> Chi-Square Goodness-of-Fit Test</h2>
<p>Most of the methods we will learn throughout this book are parametric, meaning that we are using a sample to test hypotheses about parameters (e.g., means and variances) in a population. But not all research questions involve population parameters, so parametric methods don‚Äôt always meet our needs. Most of the methods we learn also come with certain assumptions, but real-world data won‚Äôt always meet those assumptions. Nonparametric statistical tests are methods used in statistics that do not require the data to follow a specific distribution, such as the normal distribution. These tests are particularly useful when:</p>
<ul>
<li><p>The data violate assumptions required for parametric tests (e.g., normality, homogeneity of variance).</p></li>
<li><p>The data are ordinal or ranked instead of being measured on an interval or ratio scale.</p></li>
<li><p>The data contain outliers or are severely skewed.</p></li>
</ul>
<p>The first nonparametric technique we will learn is the <strong>chi-square goodness-of-fit test</strong>. If you have data on a single variable, and you want to compare it to known or expected values, you will use the chi-square goodness-of-fit test. This test will allow you to evaluate how well your observed data align with these expected values. While the expected values may sometimes represent an even distribution across groups, it is not a requirement. The key is that you already know the expected values.</p>
<p>Use this test when your goal is to determine whether a discrepancy between a set of proportions (frequencies) that you are expecting to see and a set that you have observed is not simply due to a sampling error or random chance. Let‚Äôs look at the goodness-of-fit test more closely with an example.</p>
<p>Suppose you want to investigate whether a state-level STEM enrichment program provides equitable access based on gender. Across the state, 474 students were selected to participate in the program. You would expect 237 males and 237 females, assuming a 50/50 split if there were perfect gender balance in the selection process. However, the actual frequencies are displayed in the table below.</p>
<p><strong>Gender Distribution of Participants</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Gender</th>
<th>Frequency</th>
<th>Percent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Female</td>
<td>216</td>
<td>45.6</td>
</tr>
<tr class="even">
<td>Male</td>
<td>258</td>
<td>54.4</td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td><strong>474</strong></td>
<td><strong>100</strong></td>
</tr>
</tbody>
</table>
<p>The distribution is clearly not 50/50, but is it different enough that the outcome is likely not a result of random chance? To answer this question, we apply a chi-square goodness-of-fit test. This is another way to test a hypothesis, so we follow the same steps we have already learned.</p>
<section id="step-1-state-the-research-question-and-determine-the-null-and-alternative-hypotheses." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-1-state-the-research-question-and-determine-the-null-and-alternative-hypotheses.">Step 1: State the research question and determine the null and alternative hypotheses.</h4>
<p>Typically, we can make two types of predictions for goodness-of-fit tests. We often expect all categories to be equal. We would expect a 50/50 gender split if participants are limited to only selecting between female and male. Similarly, we would expect 25% of students to choose each menu item if limited to four quality lunch options. But other times, we have reason to expect distributions to not be evenly split across options. For example, imagine we wanted to investigate the proportion of students identified as gifted by race/ethnicity. If we had participants from five different groups, we would not necessarily expect 20% of the gifted students to come from each group. Instead, we would expect that the distribution of gifted students match the percentage of students from each group in the student body overall.</p>
<p>In this example, our null hypothesis is that there is no difference in proportions by gender, or mathematically, the proportions of males and females selected are equal to the expected proportions (i.e., 50% each). The alternative hypothesis is that there is a significant difference by gender, or the proportions of males and females selected are NOT equal to expected proportions.</p>
</section>
<section id="step-2-set-the-criteria-for-a-decision.-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-2-set-the-criteria-for-a-decision.-1">Step 2: Set the criteria for a decision.</h4>
<p>We will once again use our typical alpha level of 0.05. If the p value is smaller than 0.05, we will reject the null hypothesis. The next part of this step is finding the critical value, and that brings us to a new distribution: the chi-square distribution. Like the t distribution, the chi-square distribution is a whole family of distributions that varies depending on the degrees of freedom. The chi-square distribution is a probability distribution that arises when a sum of the squares of Ôøº independent standard normal random variables is calculated. If (<strong><em>Equation broken here in original doc need fixing</em></strong>) follows a chi-square distribution with Ôøº degrees of freedom (df).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter8_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Fig 8.7: Chi-Square Distributions with Different Degrees of Freedom</figcaption>
</figure>
</div>
</div>
</div>
<p>For the chi-square goodness-of-fit test, the degrees of freedom are equal to k -1, where k = the number of categories or levels within your variable. Our variable is gender, and participants were confined to just two categories (k = 2), so we have just 1 degree of freedom. Since we are using Œ± = 0.05, we can flip to the Critical Values of Chi-Square (<span class="math inline">\(x^2\)</span>) in the appendix and find that the critical value is 3.84.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter8_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="720"></p>
<figcaption>Figure 8.8: Chi-square distribution with df = 1</figcaption>
</figure>
</div>
</div>
</div>
<p>One thing you might notice about this table of critical values is that unlike most of the tables we have used, the critical value increases as degrees of freedom increase. The reason for this will make sense when you see the formula for the test statistic. Another important point is that the chi-square test is always one-tailed, even though our alternative hypothesis does not imply any specific direction for the difference. Instead, we test for the total deviation from the expected values. We reject the null hypothesis if our observed chi-square statistic exceeds the critical value.</p>
</section>
<section id="step-3-verify-that-data-meet-necessary-assumptions-for-the-statistical-method-and-calculate-the-test-statistic." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-3-verify-that-data-meet-necessary-assumptions-for-the-statistical-method-and-calculate-the-test-statistic.">Step 3: Verify that data meet necessary assumptions for the statistical method, and calculate the test statistic.</h4>
<p>There are two data conditions that are required for the use of a chi-square test:</p>
<ol type="1">
<li><p>Observations are independent, meaning the same individual or case cannot be categorized into more than one group.</p></li>
<li><p>The expected frequency count (n) for each cell or category should be 5 or more. If your expected values are too small, that will cause problems with the calculation of the test statistic. The most common solutions to this problem are increasing your sample size to ensure sufficient observations in each cell or merge categories to achieve larger expected frequencies. You might also choose to conduct a Fisher‚Äôs exact test, which we will not detail in this book.</p></li>
</ol>
<p>When we talk about chi-square tests, we use the word ‚Äúcell.‚Äù Think of this as if you are creating a table with rows and columns. A cell is just one square in the table. It belongs to one row and one column. In this example, our table is one column (count of students) by two rows (female/male). So, we have two cells altogether.</p>
<p>The formula for the goodness-of-fit test is:</p>
<p><span class="math display">\[
\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}
\]</span></p>
<p>In this formula, Oi = the observed count of ith cell (i.e., how many individuals we observed actually fall within the cell) and Ei = the expected count of ith cell (the number of individuals that we think should be in the cell). For each cell, we would find a difference between observed and expected values, square the difference (remember, if we are adding up differences and want the answer to be something other than zero, we must square the differences first), and divide it by the expected value. We would then take these squared values for every comparison between the expected and observed pair and add them together.</p>
<p>Can you see why it is problematic if expected counts are very small? If you look at the formula for the chi-square test statistic, the expected value goes in the denominator. If we have a very low expected value, we can end up with an artificially inflated test statistic, which increases the risk of Type I error.</p>
<p>In our example, we already know the expected frequencies (a 50/50 split of 474 employees would be 237 in each group). We also have the observed frequencies from the table earlier in the chapter, so we add those values to the equation:</p>
<p><span class="math display">\[
\chi^2 = \frac{(216 - 237)^2}{237} + \frac{(258 - 237)^2}{237} = 3.72
\]</span></p>
</section>
<section id="step-4-draw-a-conclusion-for-your-research-question." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="step-4-draw-a-conclusion-for-your-research-question.">Step 4: Draw a conclusion for your research question.</h4>
<p>We compare our observed chi-square test statistic to the critical value we determined earlier. Remember, if our observed value is greater than the critical value, we reject the null. In this case, 3.72 &lt; 3.84, so we fail to reject the null. While there is not an exact 50/50 split in employees along gender lines, the difference is not large enough to be considered significant. The exact p value associated with (<strong><em>Equation broken again pls fix</em></strong>)</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter8_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="720"></p>
<figcaption>Figure 8.9: Chi-square distribution (df = 1) with critical value and observed test statistic</figcaption>
</figure>
</div>
</div>
</div>
<p>Here, we present an example of a chi-square goodness-of-fit result written in APA style.</p>
<p>A chi-square goodness-of-fit test was conducted to determine whether the state-level STEM enrichment program provides equitable access based on gender, with expected proportions for male and female participants. All assumptions for the analysis were met. The results indicated no statistically significant difference in the proportions of males and females selected for the program (<strong><em>Equation broken here</em></strong>). These findings suggest that the enrichment program provides equitable access by gender.</p>
</section>
</section>
<section id="conclusion" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">8.8</span> Conclusion</h2>
<p>Hypothesis testing bridges theoretical research questions and practical data analysis, offering a structured framework for making evidence-based decisions. By understanding statistical significance, effect sizes, and confidence intervals, researchers can draw meaningful conclusions while accounting for uncertainty and variability. For educational researchers, it is particularly important to assess both statistical and practical significance when interpreting empirical results.</p>
<p>While p values indicate whether a result is statistically significant, they do not reveal the magnitude or practical relevance of the effect. Measures of effect size, such as Cohen‚Äôs d, provide valuable context by quantifying the size of an effect, helping researchers determine its importance in real-world settings. For example, a small p value paired with a negligible effect size may lack practical significance, limiting its applicability. Therefore, when statistically significant findings are observed, it is essential to consider their implications within the research context, ensuring that the results are both statistically sound and practically meaningful. This dual evaluation enhances the relevance and impact of research findings in education and beyond.</p>
<section id="key-takeaways-for-educational-researchers-from-chapter-8" class="level3" data-number="8.8.1">
<h3 data-number="8.8.1" class="anchored" data-anchor-id="key-takeaways-for-educational-researchers-from-chapter-8"><span class="header-section-number">8.8.1</span> Key Takeaways for Educational Researchers from Chapter 8</h3>
<ul>
<li><p>Two statistical methods, one-sample t tests and Chi-square goodness-of-fit tests, are for comparing the observed statistic to a benchmark. Use a one-sample t test when comparing a sample mean to a known population mean with unknown standard deviation. Use a chi-square goodness-of-fit test when comparing observed proportions or frequencies in a single categorical variable to known or expected distributions.</p></li>
<li><p>Statistical significance (e.g., p values) indicates whether an observed effect is unlikely due to chance, while effect sizes (e.g., Cohen‚Äôs d) quantify the magnitude and practical relevance of the effect. By reporting both, education researchers can ensure their findings have actionable value, informing policy, curriculum design, or classroom interventions.</p></li>
<li><p>The correct interpretation of a 95% confidence interval (CI) for a population mean is as follows: ‚ÄúWe are 95% confident that the interval contains the true population mean.‚Äù If we were to take many random samples of fixed sample size (e.g., n = 50) from the population and compute a confidence interval for each sample, approximately 95% of those intervals would contain the true population mean. Confidence intervals help researchers communicate the degree of certainty in their findings, ensuring that conclusions account for variability and are not overly dependent on a single estimate. They are particularly beneficial when researchers want to evaluate the reliability of a point estimate or compare results across studies.</p></li>
<li><p>Larger sample sizes increase statistical power but may detect trivial differences as significant. Carefully designing studies to balance power with meaningfulness enables education researchers to use resources effectively and avoid misinterpreting results as practically relevant when they are not.</p></li>
</ul>
</section>
</section>
<section id="key-definitions-for-chapter-8" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="key-definitions-for-chapter-8"><span class="header-section-number">8.9</span> Key Definitions for Chapter 8</h2>
<p>The <strong>chi-square distribution</strong> is a probability distribution that arises when a sum of the squares of k independent standard normal random variables is calculated. If (<strong><em>Equation broken here</em></strong>)</p>
<p>follows a chi-square distribution with k degrees of freedom (df).</p>
<p>The <strong>chi-square goodness-of-fit test</strong> is a nonparametric method used to determine whether observed data frequencies match expected frequencies for a single categorical variable. This test is useful when comparing observed proportions to known or hypothesized distributions, such as evaluating gender equality in a workforce. By calculating the chi-square statistic and comparing it to a critical value, researchers can assess whether deviations from expected frequencies are due to random chance or are statistically significant.</p>
<p><strong>Cohen‚Äôs</strong> <strong><em>d</em></strong> quantifies the magnitude of the difference between two means relative to the variability in the data and provides a standardized measure of practical significance, helping to interpret the importance of the result by allowing us to express the effect size in terms of standard deviation units.</p>
<p><strong>Confidence intervals (CIs)</strong> provide an additional layer of transparency by offering a range of values likely to contain the true population parameter. The chapter highlighted the interplay between CIs and hypothesis testing, explaining that if a null value (e.g., a population mean) falls within the CI, the null hypothesis cannot be rejected.</p>
<p><strong>Effect size</strong> is a numeric measure that indicates the strength or meaningfulness of the relationship or difference between variables in a study.</p>
<p><strong>Nonparametric statistical tests</strong> are methods used in statistics that do not require the data to follow a specific distribution, such as the normal distribution.</p>
<p><strong>Type III error</strong> occurs when researchers correctly calculate statistical results but misinterpret or apply them to the wrong question or hypothesis.</p>
</section>
<section id="check-your-understanding" class="level2" data-number="8.10">
<h2 data-number="8.10" class="anchored" data-anchor-id="check-your-understanding"><span class="header-section-number">8.10</span> Check Your Understanding</h2>
<ol type="1">
<li><p><strong>When should a one-sample <em>t</em> test be used instead of a <em>z</em> test?</strong></p>
<ol type="a">
<li>When the population mean is known<br>
</li>
<li>When the population standard deviation is unknown<br>
</li>
<li>When the sample size is less than 30<br>
</li>
<li>When comparing two sample means</li>
</ol></li>
<li><p><strong>What is the formula for the degrees of freedom (<em>df</em> ) in a one-sample <em>t</em> test?</strong></p>
<ol type="a">
<li><em>df</em> = <em>n</em> + 1<br>
</li>
<li><em>df</em> = <em>n</em> √ó 2<br>
</li>
<li><em>df</em> = <em>n</em> ‚àí 1<br>
</li>
<li><em>df</em> = <em>n</em> / 2</li>
</ol></li>
<li><p><strong>Which of the following is <em>not</em> an assumption of the one-sample <em>t</em> test?</strong></p>
<ol type="a">
<li>Random sampling<br>
</li>
<li>Independence of observations<br>
</li>
<li>Population variance of 0<br>
</li>
<li>Dataset is approximately normally distributed</li>
</ol></li>
<li><p><strong>What is the purpose of calculating effect size, such as Cohen‚Äôs <em>d</em>?</strong></p>
<ol type="a">
<li>To determine statistical significance<br>
</li>
<li>To quantify the magnitude of a difference<br>
</li>
<li>To check if assumptions are met<br>
</li>
<li>To calculate degrees of freedom</li>
</ol></li>
<li><p><strong>What is the risk of using a one-tailed test when the actual effect is in the opposite direction?</strong></p>
<ol type="a">
<li>Type I error<br>
</li>
<li>Type II error<br>
</li>
<li>Type III error<br>
</li>
<li>Increased power</li>
</ol></li>
</ol>
</section>
</section>
<section id="chapter-8-one-sample-t-test-and-goodness-of-fit-analysis-in-r" class="level1 unnumbered">
<h1 class="unnumbered">Chapter 8: One-Sample t Test and Goodness-of-Fit Analysis in R</h1>
<p>This section demonstrates how to conduct a One-Sample t Test and a Chi-Square Goodness-of-Fit Test using R. These tests are useful for evaluating whether a sample mean significantly differs from a known benchmark and for comparing observed frequencies to an expected distribution. We will use the PISA 2022 U.S. dataset to illustrate these methods.</p>
<section id="one-sample-t-test" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="one-sample-t-test">1 One-Sample t Test</h2>
<p>Example: Comparing U.S. Math Scores to an International Benchmark</p>
<p>We will compare PV1MATH (math plausible value 1) for U.S. students to a benchmark value of 441, which represents the approximate mean of participants from all participating countries.</p>
<section id="define-hypothesis" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="define-hypothesis">1.1 Define Hypothesis</h3>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \text{The mean PV1MATH score is equal to } 441 \; (\mu = 441). \\
H_a &amp;: \text{The mean PV1MATH score is not equal to } 441 \; (\mu \ne 441).
\end{aligned}
\]</span></p>
</section>
<section id="conduct-the-test" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="conduct-the-test">1.2 Conduct the Test</h3>
<p><strong>(Reading data is hidden right now, but maybe should include anyways?)</strong></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract math scores </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>math_scores <span class="ot">&lt;-</span> data<span class="sc">$</span>PV1MATH </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct the one-sample t test </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>benchmark <span class="ot">&lt;-</span> <span class="dv">441</span> </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>t_test_result <span class="ot">&lt;-</span> <span class="fu">t.test</span>(math_scores, <span class="at">mu =</span> benchmark, <span class="at">alternative =</span> <span class="st">"two.sided"</span>) </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Display results </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>t_test_result </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    One Sample t-test

data:  math_scores
t = 14.804, df = 4551, p-value &lt; 2.2e-16
alternative hypothesis: true mean is not equal to 441
95 percent confidence interval:
 459.1090 464.6375
sample estimates:
mean of x 
 461.8733 </code></pre>
</div>
</div>
<p><strong>Interpretation</strong>: The results show that U.S. students scored significantly higher than the international benchmark of 441. With an average score of 461.87, the difference is large enough that it is very unlikely to have occurred by random chance (<span class="math inline">\((p &lt; 2.2 \times 10^{-16})\)</span>). The confidence interval [459.11, 464.64] tells us that, with 95% certainty, the true average score for U.S. students falls within this range. Since the entire confidence interval is above 441, we can confidently say that U.S. students outperform the international average in mathematics.</p>
</section>
<section id="calculate-effect-size-cohens-d" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="calculate-effect-size-cohens-d">1.3 Calculate Effect Size (Cohen‚Äôs d)</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract math scores </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Cohen's d </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>effect_size <span class="ot">&lt;-</span> (<span class="fu">mean</span>(math_scores) <span class="sc">-</span> benchmark) <span class="sc">/</span> <span class="fu">sd</span>(math_scores) </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>effect_size </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2194198</code></pre>
</div>
</div>
<p>Interpretation: With an effect size of 0.22, the difference between the U.S. mean and the international benchmark is statistically significant but relatively small. This means that while U.S. students score higher on average, the difference is not large enough to suggest a dramatic practical advantage.</p>
</section>
</section>
<section id="chi-square-goodness-of-fit-test-1" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="chi-square-goodness-of-fit-test-1">2 Chi-Square Goodness-of-Fit Test</h2>
<p><strong>Example: Evaluating Perception of Mathematics as Easier Than Other Subjects </strong></p>
<p>We will analyze MATHEASE, which is a binary variable (0 = No, 1 = Yes) measuring students‚Äô perceptions of whether mathematics is easier than other subjects. The goal is to test whether responses are equally distributed (50/50).</p>
<section id="define-hypothesis-1" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="define-hypothesis-1">2.1 Define Hypothesis</h3>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \text{The responses are equally distributed (50\% ``Yes'', 50\% ``No'').} \\
H_a &amp;: \text{The responses are not equally distributed (deviation from 50/50 split).}
\end{aligned}
\]</span></p>
</section>
<section id="conduct-the-test-1" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="conduct-the-test-1">2.2 Conduct the Test</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove missing values from MATHEASE </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>mathease_data <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(data<span class="sc">$</span>MATHEASE) </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(mathease_data) <span class="co">#used sample size </span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3998</code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Count occurrences of Yes (1) and No (0) </span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>observed_counts <span class="ot">&lt;-</span> <span class="fu">table</span>(mathease_data) </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>observed_counts </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>mathease_data
   0    1 
3497  501 </code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected counts under the null hypothesis (50/50 distribution) </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>expected_counts <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">sum</span>(observed_counts) <span class="sc">/</span> <span class="dv">2</span>, <span class="dv">2</span>) </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>expected_counts </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1999 1999</code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Perform chi-square test </span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>chi_sq_result <span class="ot">&lt;-</span> <span class="fu">chisq.test</span>(<span class="at">x =</span> observed_counts, <span class="at">p =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>)) </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display results </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>chi_sq_result </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Chi-squared test for given probabilities

data:  observed_counts
X-squared = 2245.1, df = 1, p-value &lt; 2.2e-16</code></pre>
</div>
</div>
<p><strong>Interpretation</strong>: The results show a highly significant difference between observed and expected responses ( X2=2245.1 , p&lt;2.2e‚àí16 ). This means that students‚Äô perceptions of whether math is easier than other subjects are far from evenly split. In reality, only 501 students (12.5%) felt math was easier, while 3497 students (87.5%) believed otherwise. The large chi-square statistic suggests this imbalance is not due to random chance but reflects a real tendency among students to find math more difficult compared to other subjects.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter7.html" class="pagination-link" aria-label="Chapter 7">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Chapter 7</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter9.html" class="pagination-link" aria-label="Chapter 9">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Chapter 9</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>